{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "matplotlib.rcParams['savefig.dpi'] = 144"
      ],
      "metadata": {
        "id": "UOqpXzSHeyJ0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "E0pQPKiqe8Ps"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Makine Öğrenimine Giriş**\n",
        "\n",
        "Öğrenmek ne anlama geliyor? Öğrenme, bir dizi gözlem yaptığımız ve geçmiş deneyimlere dayanarak sonuçlar çıkardığımız bir süreçtir. Örneğin, daha geç otobüse bindiğimde işe geç kaldığım gibi deneyimsel verilerdeki kalıpları tanımayı öğrenebiliriz. Makine Öğrenimi, bir bilgisayara aynı şeyi yapmayı, yani verilerdeki örüntüleri bulmayı öğrettiğimiz zamandır. Buradaki fikir, insanların örüntü bulma konusunda gerçekten harika, ancak büyük miktarda veriye bakma konusunda nispeten yavaş olduklarıdır. Bilgisayarların örüntüleri bulmak için eğitilmeleri gerekir, ancak elimizdeki türden verileri (csv dosyaları, resimler, vb.) inanılmaz derecede hızlı işleyebilirler.\n",
        "\n",
        "Makine Öğrenimi devriminin kökleri iki ana faktöre dayanmaktadır\n",
        "\n",
        "1.Yeni üretilen büyük miktarda veri\n",
        "\n",
        "2.Bilgisayar belleğinde ve performansında büyük bir gelişme\n",
        "\n",
        "Makine öğreniminden yararlanmak istiyorsak, bilgisayarlara örüntüleri tanımayı öğretmeyi ve bu yeteneği gerçek dünya örüntülerini çözmek için kullanmayı öğrenmemiz gerekir. Gerçekten basit bir örnekle başlayalım.\n"
      ],
      "metadata": {
        "id": "0nvPYz9CegNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.linspace(0, 1, 100)\n",
        "exp = np.random.choice([2, 3])\n",
        "y = X**exp + np.random.randn(X.shape[0]/10)\n",
        "plt.plot(X, y, '.');"
      ],
      "metadata": {
        "id": "HkCGeYgpgg2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi mümkün olan en basit yöntemlerden birini kullanarak, verilere bir doğru uydurarak tahminsel ilişkiyi oluşturacağız"
      ],
      "metadata": {
        "id": "M7dnrYilghkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.polyfit(X, y, 1)\n",
        "z = np.poly1d(p)\n",
        "plt.plot(X, y, '.')\n",
        "plt.plot(X, z(X), label=r\"Model: ${:.2f}x + {:.2f}$\".format(*p))\n",
        "plt.plot(X, X**exp, label=r'Truth: $x^{}$'.format(exp))\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "_e_U_0p_hQZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artık bu veriler için bilgisayar tarafından öğrenilen bir modelimiz var, yani \n",
        " değerini (veya bir grup değeri) kullanarak çıktıyı tahmin edebiliriz. Makine Öğrenimi bağlamında buna Doğrusal Regresyon denir ve öğrenmek için oldukça güçlü ve genel bir yöntemdir. Sadece bu örnek bile daha sonraki derslerde yanıtlayacağımız pek çok soruya kapı açmaktadır:"
      ],
      "metadata": {
        "id": "55DTnU0ShTc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model ne kadar iyi?\n",
        "2. Modele esneklik katabilir miyiz?\n",
        "3. Model genelleştirilebilir mi?\n",
        "4. Bu model bize veriler hakkında ne öğretiyor?"
      ],
      "metadata": {
        "id": "I-iMtQn3hWRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Makine Öğrenimi, denetimli öğrenme ve denetimsiz öğrenme olmak üzere iki sınıfa ayrılır. Denetimli öğrenmede, verilerimizin özellikleri ile bir tür çıktı etiketi arasında tahmin edici bir ilişki öğrenmeye çalışıyoruz. Denetimsiz öğrenmede ise herhangi bir hedef etiket kullanmadan özelliklerimizdeki eğilimleri bulmak isteriz. Denetimsiz öğrenme tipik olarak verilerin boyutluluğunu azaltmaya dayanır.\n",
        "\n",
        "Denetimli öğrenmenin genel amacı, daha sonra bu modeli orijinali temsil eden bir özellik matrisi oluşturabilecek etiketsiz verilere uygulamaktır. Bu da tahminler yapmamızı sağlar!\n",
        "\n",
        "Elbette, makine öğrenimi sadece bir araçtır, dikkatle ve düşünülerek uygulanması gereken bir araçtır. Her sorun için ideal çözüm değildir. Karşılaşabileceğimiz bazı sorunlara bir göz atalım."
      ],
      "metadata": {
        "id": "T1ZaWch2heok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Makine Öğrenimi Zorlukları**\n",
        "\n",
        "Modeller büyük ölçüde önyargılı olabilir ve bu nedenle genellemeyi idare edecek kadar esnek olmayabilir. Orijinal fonksiyonumuzu daha geniş bir aralıkta çizelim ve önceki modeli kullanalım."
      ],
      "metadata": {
        "id": "35iydtENhtwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.linspace(0, 2, 100)\n",
        "y = X**exp + np.random.randn(X.shape[0]/10)\n",
        "plt.plot(X, z(X), label=r\"${:.2f}x + {:.2f}$\".format(*p))\n",
        "plt.plot(X, y, '.', label=r'$x^{}$'.format(exp))\n",
        "plt.legend();\n"
      ],
      "metadata": {
        "id": "kjMB2kMBhx6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model, başlangıçta verilerimizi dikkate aldığımız aralık için oldukça iyi çalışıyor, ancak dikkate aldığımız aralığın dışındaki özelliklere iyi genelleme yapmayacağını görebiliyoruz. Bu genel bir sorundur; eğitim verilerimizin üzerinde tahminler yapmayı beklediğimiz iyi örneklenmiş bir dağılım içermesine dikkat etmeliyiz (ya da eğitim verilerimizin etki alanının ötesinde tahminler yapabilmemiz gerektiğini söyleyen bazı ön bilgilere sahip olmalıyız). Makine öğrenimi daha önce gördüğü verilerdeki örüntüleri bulur ve görmediği veriler üzerinde her zaman iyi tahminler yapamaz.\n",
        "\n",
        "Modele daha fazla parametre ekleyerek bunu düzeltmeye çalışalım.\n"
      ],
      "metadata": {
        "id": "dLEYieKZiW0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.polyfit(X, y, 15)\n",
        "z = np.poly1d(p)\n",
        "plt.figure(figsize=[14, 6])\n",
        "plt.plot(X, z(X), label=r\"${:.2f}x^{{15}} + {:.2f}x^{{14}} + ... + {:.2f}$\".format(*p[[0, 1, -1]]))\n",
        "plt.plot(X, y, '.', label=r'$x^{}$'.format(exp))\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "mEk7N9OUic1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mükemmel bir uyum gibi görünüyor! Belki de fazla iyi? Görünüşe göre model, gerçek olmadığını bildiğimiz verilerdeki küçük dalgalanmalara uyuyor (gerçek veriler basit bir üstelden türetilmiştir). Tekrar genelleştirmeyi deneyelim."
      ],
      "metadata": {
        "id": "7GdpYWeBi6ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.linspace(0, 2.5, 100)\n",
        "y = X**exp + np.random.randn(X.shape[0])/10\n",
        "plt.plot(X, z(X), label=r\"model\")\n",
        "plt.plot(X, y, '.', label=r'$x^{}$'.format(exp))\n",
        "plt.legend();\n"
      ],
      "metadata": {
        "id": "fh0tlACci7N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yine mi! Bu oldukça kötü. Bu, modele çok fazla esneklik tanıdığımız ve verideki genelleştirilemeyen gürültüye uyduğu bir aşırı uyum örneğidir."
      ],
      "metadata": {
        "id": "4cN5HtwGjfxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scikit-Learn**\n",
        "\n",
        "Makine öğrenimini gerçekleştirmek için scikit-learn paketini kullanacağız ve farklı makine öğrenimi modellerine ve yardımcı programlarına birleşik sınıf tabanlı bir arayüz sunacağız. Scikit-learn, makine öğrenimi için gerekli yöntemleri uygulayan bir Estimator sınıfı fikrine dayanmaktadır.\n",
        "\n",
        "Her tahmin edici nesnesi, argüman olarak bir özellik matrisi X ve bir etiket vektörü y kabul eden bir fit yönteminin yanı sıra bir argüman olarak bir özellik matrisi X kabul eden bir tahmin yöntemini uygulayacaktır. Bir örnek üzerinden gidelim.\n",
        "\n",
        "Öncelikle istediğimiz tahmin ediciyi içe aktarmamız gerekecek, bu durumda bir LinearRegression (bunu her ad alanı için yalnızca bir kez yapmamız gerekir, bu yalnızca bir Python sınıfıdır)."
      ],
      "metadata": {
        "id": "jG01IPjAjgrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "ietvUQa_jzFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi bu sınıfın bir örneğini oluşturabilir ve herhangi bir hiper parametreyi oluşturmaya aktarabiliriz. LinearRegression'ın fit_intercept ve normalize olmak üzere iki ana hiper parametresi vardır. Bunların varsayılan değerleri vardır, ancak biz bunları burada açıkça belirteceğiz."
      ],
      "metadata": {
        "id": "2ZFnGJCvj3bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(fit_intercept=True, normalize=False)\n",
        "lr"
      ],
      "metadata": {
        "id": "kQ9ipM7Aj6Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi bu nesneyi daha önceki verilerimize uydurmak için kullanabiliriz. Bunu yapmak için fit yöntemini kullanacağız. X vektörünü, tek boyutlu bir vektör yerine tek sütunlu bir özellik matrisi olacak şekilde yeniden şekillendirmemiz gerekecek."
      ],
      "metadata": {
        "id": "UNIiwwtLkAZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(X.reshape(-1, 1), y)\n"
      ],
      "metadata": {
        "id": "igtmwmS7kCxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit metodu fit işlemini gerçekleştirir ve fit edilen parametreleri nesnenin durumuna dahili olarak kaydeder. İstersek bunları görebiliriz."
      ],
      "metadata": {
        "id": "GPgaqCpKkGvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr.coef_, lr.intercept_"
      ],
      "metadata": {
        "id": "XLrUYLKIkJRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametreleri örneğin içine kaydetmek, tüm nesneyi seçmemize ve parametreleri modelin içine kaydetmemize izin verdiği için son derece kullanışlıdır.\n",
        "\n",
        "Son olarak tahminler yapmak için predict metodunu kullanabiliriz."
      ],
      "metadata": {
        "id": "apoE6lt8kNIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr.predict(X.reshape(-1, 1))\n",
        "plt.plot(X, y, '.', label='data')\n",
        "plt.plot(X, predictions, label='model')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "_DeUHExSkPIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doğrusal modelleri daha sonraki bir derste daha ayrıntılı olarak inceleyeceğiz, ancak bu modeli daha iyi hale getirmek istiyorsak, bazı daha iyi özellikler tasarlamamız gerekecek. Nereye gittiğimize dair bir fikir edinmek için biraz daha scikit-learn makinesi kullanalım."
      ],
      "metadata": {
        "id": "5Y8A3zplkfZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('polynomial_transform', PolynomialFeatures(3)),\n",
        "    ('linear_fit', LinearRegression())\n",
        "])\n",
        "\n",
        "pipe.fit(X.reshape(-1, 1), y)\n",
        "\n",
        "predictions = pipe.predict(X.reshape(-1, 1))\n",
        "plt.plot(X, y, '.', label='data')\n",
        "plt.plot(X, predictions, label='model')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "jEOwzTY8kf-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu genelleştirilebilir mi?"
      ],
      "metadata": {
        "id": "QGeDKooYlH_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.linspace(0, 4, 100)\n",
        "y = X**exp + np.random.randn(X.shape[0])/10\n",
        "predictions = pipe.predict(X.reshape(-1, 1))\n",
        "plt.plot(X, y, '.', label='data')\n",
        "plt.plot(X, predictions, label='model')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "O4mROPzelKEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}